# LDA Quick Reference - Key Formulas & Concepts

## ğŸ¯ Core Objective

**Find vector w that maximizes**:
```
J(w) = Between-Class Variance / Within-Class Variance
     = (w^T S_B w) / (w^T S_W w)
```

---

## ğŸ“ Key Matrices

### Between-Class Scatter (S_B)
```
S_B = (Î¼â‚ - Î¼â‚‚)(Î¼â‚ - Î¼â‚‚)^T
```
Measures: How far apart are the class means?

### Within-Class Scatter (S_W)
```
S_W = Î£â‚ + Î£â‚‚
```
Measures: How much variance within each class?

### Optimal Direction
```
w = S_W^(-1) (Î¼â‚ - Î¼â‚‚)
```

---

## ğŸ“Š Statistical Tests

### Two-Sample t-Test
```
t = (xÌ„â‚ - xÌ„â‚‚) / âˆš(sâ‚Â²/nâ‚ + sâ‚‚Â²/nâ‚‚)
```

**Interpretation**:
- p < 0.001: â˜…â˜…â˜… Extremely significant
- p < 0.01:  â˜…â˜…â˜† Very significant  
- p < 0.05:  â˜…â˜†â˜† Significant
- p â‰¥ 0.05:  â˜†â˜†â˜† Not significant

---

## ğŸ² Decision Rule (Bayes)

**Optimal Threshold** (equal priors & variances):
```
threshold = (Î¼_male + Î¼_female) / 2
```

**Classification**:
```
If LD1_score < threshold â†’ Class 1
If LD1_score â‰¥ threshold â†’ Class 2
```

---

## ğŸ“ˆ Performance Metrics

### Accuracy
```
Accuracy = Correct Predictions / Total Predictions
```

### Confidence Interval (95%)
```
CI = Accuracy Â± 1.96 Ã— âˆš[Accuracy Ã— (1-Accuracy) / n]
```

### Effect Size (Cohen's d)
```
d = (Î¼â‚ - Î¼â‚‚) / âˆš[(sâ‚Â² + sâ‚‚Â²) / 2]
```
- Small: |d| < 0.2
- Medium: |d| â‰ˆ 0.5
- Large: |d| > 0.8

---

## ğŸ”¢ Standardization (Z-score)

```
z = (x - Î¼) / Ïƒ
```

**Result**: Mean = 0, Std = 1

---

## ğŸ“ Key Assumptions

1. âœ“ **Multivariate Normality**: Each class ~ N(Î¼, Î£)
2. âœ“ **Equal Covariance**: Î£â‚ â‰ˆ Î£â‚‚
3. âœ“ **Independence**: Samples drawn independently
4. âœ“ **Linearity**: Decision boundary is linear

---

## ğŸ’¡ Quick Interpretation Guide

| p-value | Separation | Action |
|---------|------------|--------|
| < 0.001 | Excellent | âœ… Trust results |
| 0.001-0.05 | Good | âœ… Use with confidence |
| 0.05-0.10 | Marginal | âš ï¸ Be cautious |
| > 0.10 | None | âŒ Rethink approach |

| Accuracy | Quality | Interpretation |
|----------|---------|----------------|
| 90-100% | Excellent | Highly reliable |
| 80-90% | Good | Reliable |
| 70-80% | Fair | Acceptable |
| 60-70% | Weak | Barely useful |
| 50-60% | Poor | Not better than random |

---

## ğŸ” Confusion Matrix

```
                Predicted
              Male   Female
Actual  Male   TP      FN
       Female  FP      TN
```

### Derived Metrics
```
Sensitivity = TP / (TP + FN)    [Recall for males]
Specificity = TN / (TN + FP)    [Recall for females]
Precision   = TP / (TP + FP)    [Male prediction accuracy]
F1-Score    = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
```

---

## ğŸ¯ Fisher's Discriminant (Intuition)

**Goal**: Project high-dimensional data to 1D line such that:
- âœ… Class means are far apart (maximize)
- âœ… Within-class spread is small (minimize)

**Analogy**: Finding the best viewing angle to see two clusters as separate.

---

## ğŸ“š LDA vs PCA

| Aspect | PCA | LDA |
|--------|-----|-----|
| Type | Unsupervised | Supervised |
| Uses labels? | âŒ No | âœ… Yes |
| Maximizes | Total variance | Class separation |
| # Components | Up to n features | Up to k-1 classes |
| Best for | Visualization | Classification |

---

## âš¡ One-Line Summary

**LDA finds the direction that maximally separates classes by maximizing the ratio of between-class to within-class variance.**

---

## ğŸ§® Example Calculation

Given two classes with:
- Male: Î¼â‚ = -2.5, Ïƒâ‚ = 1.2, nâ‚ = 100
- Female: Î¼â‚‚ = 1.8, Ïƒâ‚‚ = 1.1, nâ‚‚ = 120

**Threshold**:
```
threshold = (-2.5 + 1.8) / 2 = -0.35
```

**t-statistic**:
```
t = (-2.5 - 1.8) / âˆš(1.2Â²/100 + 1.1Â²/120)
  = -4.3 / 0.149
  = -28.86
```

**Conclusion**: p << 0.001, extremely significant separation!

**Classification Rule**:
```
If LD1 < -0.35 â†’ Male
If LD1 â‰¥ -0.35 â†’ Female
```

---

## ğŸ’» Code-to-Theory Mapping

| Code | Theory |
|------|--------|
| `StandardScaler()` | z = (x - Î¼) / Ïƒ |
| `LinearDiscriminantAnalysis()` | w = S_W^(-1)(Î¼â‚ - Î¼â‚‚) |
| `lda.fit_transform()` | y = w^T x |
| `stats.ttest_ind()` | t = (xÌ„â‚ - xÌ„â‚‚) / SE |
| `threshold = (m1 + m2)/2` | Bayes optimal decision |
| `accuracy` | Î¸Ì‚ = correct / total |